{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f9b8abea348>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import random\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "0 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "1 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "2 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "3 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "4 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "5 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "6 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "7 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "8 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "9 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "10 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "11 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "12 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "13 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "14 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "15 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "16 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "17 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "18 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "19 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "20 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "21 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "22 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "23 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "24 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "25 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "26 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "27 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "28 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "29 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "30 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "31 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "32 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "33 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "34 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "35 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "36 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "37 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "38 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "39 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "40 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "41 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "42 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "43 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "44 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "45 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "46 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "47 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "48 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "49 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "50 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "51 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "52 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "53 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "54 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "55 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "56 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "57 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "58 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "59 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "60 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "61 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "62 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "63 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "64 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "65 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "66 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "67 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "68 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "69 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "70 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "71 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "72 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "73 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "74 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "75 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "76 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "77 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "78 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "79 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "80 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "81 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "82 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "83 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "84 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "85 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "86 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "87 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "88 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "89 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "90 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "91 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "92 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "93 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "94 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "95 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "96 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "97 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "98 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "99 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "100 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "101 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "102 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "103 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "104 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "105 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "106 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "107 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "108 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "109 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "110 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "111 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "112 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "113 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "114 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "115 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "116 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "117 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "118 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "119 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "120 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "121 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "122 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "123 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "124 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "125 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "126 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "127 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "128 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "129 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "130 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "131 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "132 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "133 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "134 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "135 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "136 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "137 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "138 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "139 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "140 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "141 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "142 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "143 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "144 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "145 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "146 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "147 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "148 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "149 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "150 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "151 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "152 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "153 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "154 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "155 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "156 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "157 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "158 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "159 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "160 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "161 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "162 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "163 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "164 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "165 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "166 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "167 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "168 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "169 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "170 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "171 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "172 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "173 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "174 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "175 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "176 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "177 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "178 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "179 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "180 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "181 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "182 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "183 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "184 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "185 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "186 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "187 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "188 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "189 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "190 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "191 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "192 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "193 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "194 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "195 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "196 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "197 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "198 nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "199 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "200 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "201 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "202 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "203 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "204 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "205 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "206 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "207 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "208 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "209 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "210 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "211 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "212 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "213 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "214 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "215 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "216 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "217 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "218 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "219 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "220 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "221 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "222 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "223 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "224 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "225 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "226 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "227 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "228 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "229 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "230 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "231 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "232 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "233 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "234 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "235 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "236 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "237 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "238 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "239 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "240 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "241 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "242 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "243 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "244 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "245 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "246 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "247 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "248 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "249 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "250 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "251 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "252 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "253 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "254 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "255 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "256 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "257 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "258 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "259 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "260 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "261 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "262 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "263 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "264 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "265 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "266 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "267 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "268 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "269 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "270 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "271 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "272 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "273 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "274 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "275 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "276 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "277 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "278 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "279 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "280 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "281 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "282 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "283 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "284 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "285 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "286 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "287 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "288 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "289 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "290 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "291 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "292 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "293 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "294 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "295 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "296 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "297 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "298 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "299 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "300 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "301 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "302 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "303 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "304 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "305 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "306 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "307 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "308 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "309 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "310 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "311 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "312 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "313 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "314 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "315 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "316 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "317 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "318 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "319 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "320 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "321 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "322 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "323 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "324 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "325 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "326 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "327 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "328 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "329 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "330 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "331 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "332 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "333 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "334 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "335 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "336 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "337 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "338 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "339 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "340 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "341 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "342 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "343 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "344 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "345 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "346 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "347 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "348 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "349 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "350 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "351 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "352 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "353 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "354 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "355 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "356 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "357 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "358 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "359 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "360 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "361 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "362 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "363 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "364 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "365 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "366 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "367 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "368 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "369 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "370 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "371 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "372 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "373 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "374 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "375 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "376 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "377 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "378 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "379 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "380 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "381 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "382 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "383 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "384 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "385 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "386 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "387 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "388 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "389 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "390 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "391 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "392 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "393 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "394 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "395 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "396 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "397 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "398 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "399 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "400 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "401 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "402 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "403 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "405 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "406 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "407 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "408 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "409 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "410 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "411 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "412 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "413 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "414 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "415 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "416 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "417 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "418 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "419 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "420 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "421 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "422 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "423 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "424 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "425 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "426 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "427 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "428 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "429 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "430 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "431 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "432 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "433 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "434 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "435 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "436 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "437 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "438 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "439 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "440 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "441 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "442 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "443 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "444 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "445 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "446 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "447 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "448 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "449 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "450 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "451 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "452 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "453 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "454 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "455 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "456 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "457 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "458 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "459 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "460 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "461 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "462 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "463 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "464 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "465 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "466 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "467 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "468 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "469 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "470 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "471 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "472 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "473 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "474 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "475 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "476 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "477 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "478 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "479 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "480 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "481 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "482 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "483 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "484 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "485 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "486 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "487 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "488 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "489 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "490 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "491 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "492 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "493 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "494 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "495 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "496 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "497 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "498 nan\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 3])\n",
      "499 nan\n",
      "\n",
      "-2.8348e+06  1.3658e+00 -4.3050e-01  ...  -5.3416e-01  4.3940e-01         nan\n",
      "-4.0874e+05  3.5052e-01  9.2618e-01  ...  -3.2482e-02  2.1754e-01         nan\n",
      "-3.2997e+01 -1.8523e+00  2.7550e-01  ...   3.1884e-01  7.5721e-01         nan\n",
      "                ...                   ⋱                   ...                \n",
      "-1.0439e+07 -1.0351e+00  1.0795e+00  ...   8.1587e-01 -3.9227e+00         nan\n",
      "-9.9611e+06 -9.3700e-01  1.9216e+00  ...   1.7661e-01 -3.6735e+00         nan\n",
      "-9.8098e+06  7.4690e-01 -6.1011e-01  ...  -6.7176e-01 -3.0582e+00         nan\n",
      "[torch.FloatTensor of size 22x300]\n",
      " \n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "  nan   nan   nan\n",
      "[torch.FloatTensor of size 300x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open('../train_data/alpine-1.csv', newline='') as f:\n",
    "  reader = csv.reader(f)\n",
    "  row1 = next(reader) \n",
    "\n",
    "data_matrix_alpine = np.genfromtxt('../train_data/alpine-1.csv', delimiter=',', skip_header=1, skip_footer=1)\n",
    "data_shape = data_matrix_alpine.shape\n",
    "data_matrix_alpine_input = data_matrix_alpine[:,3:]\n",
    "data_shape_input = data_matrix_alpine_input.shape\n",
    "data_matrix_alpine_output = data_matrix_alpine[:,0:3]\n",
    "data_shape_output = data_matrix_alpine_output.shape\n",
    "# print(data_matrix_alpine.shape)\n",
    "# print(data_matrix_alpine_input.shape)\n",
    "# print(data_matrix_alpine_output.shape)\n",
    "\n",
    "INPUT_DIM = data_shape_input[1]\n",
    "HIDDEN1_UNITS = 300\n",
    "OUTPUT_DIM = data_shape_output[1]\n",
    "#HIDDEN2_UNITS = 600\n",
    "BATCH_SIZE = 64\n",
    "ITERATIONS = 500\n",
    "\n",
    "learning_rate = 1e-6\n",
    "\n",
    "dtype = torch.FloatTensor  # enable CUDA here if you like\n",
    "\n",
    "random.shuffle(data_matrix_alpine) # TODO just training data\n",
    "\n",
    "data_matrix_alpine_input_torch = torch.from_numpy(data_matrix_alpine_input)\n",
    "data_matrix_alpine_input_torch = data_matrix_alpine_input_torch.float()\n",
    "data_matrix_alpine_output_torch = torch.from_numpy(data_matrix_alpine_output)\n",
    "data_matrix_alpine_output_torch = data_matrix_alpine_output_torch.float()\n",
    "\n",
    "# Randomly initialize weights\n",
    "w1 = torch.randn(INPUT_DIM, HIDDEN1_UNITS).type(dtype)\n",
    "w2 = torch.randn(HIDDEN1_UNITS, OUTPUT_DIM).type(dtype)\n",
    "\n",
    "#w = Variable(torch.randn(data_matrix_alpine_input.shape[0], data_matrix_alpine_input.shape[1]).type(dtype), requires_grad=True)\n",
    "#b = Variable(torch.randn(1, data_matrix_alpine_input[1]).type(dtype), requires_grad=True)\n",
    "\n",
    "\n",
    "for i in range(ITERATIONS):\n",
    "    # ITERATIONS * BATCH_SIZE\n",
    "    # Forward pass: compute predicted y\n",
    "    x_batch = data_matrix_alpine_input_torch[(i*BATCH_SIZE)%ITERATIONS:(i*BATCH_SIZE)%ITERATIONS+BATCH_SIZE]\n",
    "    print(x_batch.shape)\n",
    "    y_batch = data_matrix_alpine_output_torch[(i*BATCH_SIZE)%ITERATIONS:(i*BATCH_SIZE)%ITERATIONS+BATCH_SIZE]\n",
    "    print(y_batch.shape)\n",
    "    h = x_batch.mm(w1)\n",
    "    if(print(h)\n",
    "    h_relu = h.clamp(min=0)\n",
    "    y_pred = h_relu.mm(w2)\n",
    "    \n",
    "    loss = (torch.log(y_pred - y_batch).pow(2).sum())\n",
    "    print(i, loss)\n",
    "\n",
    "    # Backprop to compute gradients of w1 and w2 with respect to loss\n",
    "    grad_y_pred = 2.0 * (y_pred - y_batch)\n",
    "    grad_w2 = h_relu.t().mm(grad_y_pred)\n",
    "    grad_h_relu = grad_y_pred.mm(w2.t())\n",
    "    grad_h = grad_h_relu.clone()\n",
    "    grad_h[h < 0] = 0\n",
    "    grad_w1 = x_batch.t().mm(grad_h)\n",
    "\n",
    "    # Update weights using gradient descent\n",
    "    #print(grad_w1)\n",
    "    #print(grad_w2)\n",
    "    w1 -= learning_rate * grad_w1\n",
    "    w2 -= learning_rate * grad_w2\n",
    "\n",
    "print(w1, w2)\n",
    "\n",
    "# class ActuatorNetwork(nn.Module):\n",
    "#     def __init__(self, input_size, output_size, BATCH_SIZE, TAU, LEARNING_RATE): #??\n",
    "#         super(ActorNetwork, self).__init__()\n",
    "        \n",
    "#         self.BATCH_SIZE = BATCH_SIZE\n",
    "#         self.TAU = TAU\n",
    "#         self.LEARNING_RATE = LEARNING_RATE\n",
    "\n",
    "#         self.h0 = nn.Linear(state_size, HIDDEN1_UNITS)\n",
    "#         self.h1 = nn.Linear(HIDDEN1_UNITS, HIDDEN2_UNITS)\n",
    "#         self.steering = nn.Linear(HIDDEN2_UNITS, 1)\n",
    "#         self.acceleration = nn.Linear(HIDDEN2_UNITS, 1)\n",
    "#         self.brake = nn.Linear(HIDDEN2_UNITS, 1)\n",
    "\n",
    "#         self.steering.weight.data.normal_(0., 1e-4)\n",
    "#         self.acceleration.weight.data.normal_(0., 1e-4)\n",
    "#         self.brake.weight.data.normal_(0., 1e-4)\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         x = F.relu(self.h0(x))\n",
    "#         x = F.relu(self.h1(x))\n",
    "#         s = F.tanh(self.steering(x))\n",
    "#         a = F.sigmoid(self.acceleration(x))\n",
    "#         b = F.sigmoid(self.brake(x))\n",
    "#         return torch.cat((s, a, b), 1)\n",
    "\n",
    "# def calc_scores(data_sensor, actuator_data):\n",
    "#     lookup_tensor = Variable(torch.LongTensor(data_sensor))\n",
    "#     embed = w[lookup_tensor] + b # TODO Sounds wrong to me\n",
    "#     score = embed.data.sub(actuator_data)\n",
    "    \n",
    "#     return torch.matmul(score, score)\n",
    "\n",
    "# for ITER in range(100):\n",
    "    \n",
    "#     # train\n",
    "#     random.shuffle(data_matrix_alpine_input) # TODO just training data\n",
    "#     train_loss = 0.0\n",
    "#     start = time.time()\n",
    "    \n",
    "#     for i in range(data_shape[0]):\n",
    "        \n",
    "#         sensor_data = data_matrix_alpine_input[i]\n",
    "#         actuator_data = data_matrix_alpine_output[i]\n",
    "        \n",
    "#         # forward pass\n",
    "#         scores = calc_scores(data_sensor, actuator_data) \n",
    "#         target = Variable(torch.LongTensor([actuator_data]))        \n",
    "#         loss = nn.CrossEntropyLoss()\n",
    "#         output = loss(scores, target)\n",
    "#         train_loss += output.data[0]        \n",
    "        \n",
    "#         # backward pass (compute gradients)\n",
    "#         output.backward()\n",
    "\n",
    "#         # update weights with SGD\n",
    "#         lr = 0.01\n",
    "#         w.data -= lr * w.grad.data\n",
    "#         b.data -= lr * b.grad.data\n",
    "\t\n",
    "# \t# clear gradients for next step\n",
    "#         w.grad.data.zero_()\n",
    "#         b.grad.data.zero_()\n",
    "        \n",
    "#     print(\"iter %r: train loss/sent=%.4f, time=%.2fs\" % \n",
    "#           (ITER, train_loss/len(train), time.time()-start))\n",
    "\n",
    "#     # evaluate\n",
    "#     correct = 0.0\n",
    "#     for words, tag in dev:\n",
    "#         scores = calc_scores(words)\n",
    "#         predict = scores.data.cpu().numpy().argmax(axis=1)\n",
    "#         if predict == tag:\n",
    "#             correct += 1\n",
    "    \n",
    "#     print(\"iter %r: test acc=%.4f\" % \n",
    "#           (ITER, correct/len(dev)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('../train_data/alpine-1.csv', newline='') as f:\n",
    "  reader = csv.reader(f)\n",
    "  row1 = next(reader) \n",
    "#print(row1)\n",
    "#print(len(row1))\n",
    "\n",
    "data_matrix_aalborg = np.genfromtxt('../train_data/alpine-1.csv', delimiter=',', skip_header=1, skip_footer=1)\n",
    "\n",
    "#print(data_matrix_aalborg[5000:5010])\n",
    "#print(data_matrix_aalborg.shape)\n",
    "\n",
    "input_length = 22\n",
    "output_length = 3\n",
    "HIDDEN_DIM = 32\n",
    "BATCH_SIZE = 5\n",
    "SEQ_LEN = 5\n",
    "\n",
    "lstm = nn.LSTM(input_length, output_length)  # Input dim is 3, output dim is 3\n",
    "inputs = [autograd.Variable(torch.randn((1, input_length)))\n",
    "          for _ in range(SEQ_LEN)]  # make a sequence of length 5\n",
    "\n",
    "# initialize the hidden state.\n",
    "hidden = (autograd.Variable(torch.randn(1, 1, HIDDEN_DIM)),\n",
    "          autograd.Variable(torch.randn((1, 1, HIDDEN_DIM))))\n",
    "#for i in inputs:\n",
    "    # Step through the sequence one element at a time.\n",
    "    # after each step, hidden contains the hidden state.\n",
    "    #out, hidden = lstm(i.view(1, 1, -1), hidden)\n",
    "\n",
    "# alternatively, we can do the entire sequence all at once.\n",
    "# the first value returned by LSTM is all of the hidden states throughout\n",
    "# the sequence. the second is just the most recent hidden state\n",
    "# (compare the last slice of \"out\" with \"hidden\" below, they are the same)\n",
    "# The reason for this is that:\n",
    "# \"out\" will give you access to all hidden states in the sequence\n",
    "# \"hidden\" will allow you to continue the sequence and backpropagate,\n",
    "# by passing it as an argument  to the lstm at a later time\n",
    "# # Add the extra 2nd dimension\n",
    "inputs = torch.cat(inputs).view(len(inputs), 1, -1)\n",
    "hidden = (autograd.Variable(torch.randn(1, 1, out)), autograd.Variable(\n",
    "    torch.randn((1, 1, output_length))))  # clean out hidden state\n",
    "out, hidden = lstm(inputs, hidden)\n",
    "print(out)\n",
    "print(hidden)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LSTMTagger(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim hidden_dim, vocab_size, tagset_size):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim)\n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "    def init_hidden(self):\n",
    "        # Before we've done anything, we dont have any hidden state.\n",
    "        # Refer to the Pytorch documentation to see exactly\n",
    "        # why they have this dimensionality.\n",
    "        # The axes semantics are (num_layers, minibatch_size, hidden_dim)\n",
    "        return (autograd.Variable(torch.zeros(1, 1, self.hidden_dim)),\n",
    "                autograd.Variable(torch.zeros(1, 1, self.hidden_dim)))\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        lstm_out, self.hidden = self.lstm(\n",
    "            embeds.view(len(sentence), 1, -1), self.hidden)\n",
    "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
    "        tag_scores = F.log_softmax(tag_space)\n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LSTMTagger(HIDDEN_DIM, len(word_to_ix), len(tag_to_ix))\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "# See what the scores are before training\n",
    "# Note that element i,j of the output is the score for tag j for word i.\n",
    "inputs = prepare_sequence(training_data[0][0], word_to_ix)\n",
    "tag_scores = model(inputs)\n",
    "print(tag_scores)\n",
    "\n",
    "for epoch in range(300):  # again, normally you would NOT do 300 epochs, it is toy data\n",
    "    for sentence, tags in training_data:\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Also, we need to clear out the hidden state of the LSTM,\n",
    "        # detaching it from its history on the last instance.\n",
    "        model.hidden = model.init_hidden()\n",
    "\n",
    "        # Step 2. Get our inputs ready for the network, that is, turn them into\n",
    "        # Variables of word indices.\n",
    "        sentence_in = prepare_sequence(sentence, word_to_ix)\n",
    "        targets = prepare_sequence(tags, tag_to_ix)\n",
    "\n",
    "        # Step 3. Run our forward pass.\n",
    "        tag_scores = model(sentence_in)\n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        #  calling optimizer.step()\n",
    "        loss = loss_function(tag_scores, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# See what the scores are after training\n",
    "inputs = prepare_sequence(training_data[0][0], word_to_ix)\n",
    "tag_scores = model(inputs)\n",
    "# The sentence is \"the dog ate the apple\".  i,j corresponds to score for tag j\n",
    "#  for word i. The predicted tag is the maximum scoring tag.\n",
    "# Here, we can see the predicted sequence below is 0 1 2 0 1\n",
    "# since 0 is index of the maximum value of row 1,\n",
    "# 1 is the index of maximum value of row 2, etc.\n",
    "# Which is DET NOUN VERB DET NOUN, the correct sequence!\n",
    "print(tag_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
